{"cells":[{"cell_type":"markdown","source":["# [Scalable Data Science](http://www.math.canterbury.ac.nz/~r.sainudiin/courses/ScalableDataScience/)\n\n\n### prepared by [Akinwande Atanda](https://nz.linkedin.com/in/akinwande-atanda)\n\n*supported by* [![](https://raw.githubusercontent.com/raazesh-sainudiin/scalable-data-science/master/images/databricks_logoTM_200px.png)](https://databricks.com/)\nand \n[![](https://raw.githubusercontent.com/raazesh-sainudiin/scalable-data-science/master/images/AWS_logoTM_200px.png)](https://www.awseducate.com/microsite/CommunitiesEngageHome)\n\n\n## [Tweet Analytics](https://github.com/aaa121/Spark-Tweet-Streaming-Presentation-May-2016)"],"metadata":{}},{"cell_type":"markdown","source":["## Creating Machine Learning Pipeline with Loop\n* The loop is created to test the sentitive of the designed algorithm to elasticNetParam\n* Read the Spark ML documentation for Logistic Regression\n* The dataset \"pos_neg_category\" can be split into two or three categories as done in previous note. In this note, the dataset is randomly split into training, validating and testing data\n* This notebook can be upload to create a job for scheduled training, validating and testing of the logistic classifier algorithm"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml import *\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import *\nfrom pyspark.ml.classification import *\nfrom pyspark.ml.tuning import *\nfrom pyspark.ml.evaluation import *\nfrom pyspark.ml.regression import *"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["df = table(\"pos_neg_category\")"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["lrARValidate =[]\nlrARTest =[]\nparam = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\nfor p in param:\n  bin = Binarizer(inputCol = \"category\", outputCol = \"label\", threshold = 0.5) # Positive reviews > 0.5 threshold\n  tok = Tokenizer(inputCol = \"review\", outputCol = \"word\") #Note: The column \"words\" in the original table can also contain sentences that will be tokenized\n  hashTF = HashingTF(inputCol = tok.getOutputCol(), numFeatures = 5000, outputCol = \"features\")\n  lr = LogisticRegression(maxIter = 10, regParam = 0.0001, elasticNetParam = p)\n  pipeline = Pipeline(stages = [bin, tok, hashTF, lr])\n  (trainingData, validateData, testData) = df.randomSplit([0.6, 0.3, 0.1])\n  model = pipeline.fit(trainingData)\n  validateModel=model.transform(validateData)\n  evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"precision\")\n  accuracyValidateSet = evaluator.evaluate(validateModel)\n  testModel=model.transform(testData)\n  accuracyTestSet = evaluator.evaluate(testModel)\n#   print(\"Logistic Regression Classifier Accuracy Rate for Validation Dataset = %g \" % (accuracyValidateSet))\n#   print(\"Logistic Regression Classifier Accuracy Rate for Test Dataset = %g \" % (accuracyTestSet))\n#   print(\"Test Error = %g \" % (1.0 - accuracy))\n  lrARValidate +=[(p,accuracyValidateSet)]\n  lrARTest +=[(p,accuracyTestSet)]"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["lrARValidate"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["lrARTest"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["print(\"Logistic Regression Classifier Accuracy Rate for Validation Dataset= \", lrARValidate)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["print(\"Logistic Regression Classifier Accuracy Rate for Test Dataset= \", lrARTest)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["#display(predictionModel.select(\"label\",\"prediction\", \"words\", \"probability\")) # Prob of being 0 (negative) against 1 (positive)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#predictionModel.select(\"label\",\"prediction\", \"words\", \"probability\").show(10) # Prob of being 0 (negative) against 1 (positive)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["# [Scalable Data Science](http://www.math.canterbury.ac.nz/~r.sainudiin/courses/ScalableDataScience/)\n\n\n### prepared by [Akinwande Atanda](https://nz.linkedin.com/in/akinwande-atanda)\n\n*supported by* [![](https://raw.githubusercontent.com/raazesh-sainudiin/scalable-data-science/master/images/databricks_logoTM_200px.png)](https://databricks.com/)\nand \n[![](https://raw.githubusercontent.com/raazesh-sainudiin/scalable-data-science/master/images/AWS_logoTM_200px.png)](https://www.awseducate.com/microsite/CommunitiesEngageHome)\n\n\n## [Tweet Analytics](https://github.com/aaa121/Spark-Tweet-Streaming-Presentation-May-2016)"],"metadata":{}}],"metadata":{"name":"TA03_03_binary_classification_with_Loop","notebookId":127965},"nbformat":4,"nbformat_minor":0}
